{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5d29f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea32921",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70aa9ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0956,  0.3544, -0.0021], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "801433f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9044, 2.3544, 1.9979], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x + 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc4006f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0956,  0.3544, -0.0021], requires_grad=True)\n",
      "tensor([1.9044, 2.3544, 1.9979], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x000002AFED6EFA00>\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1609260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y * y * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ea996e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.8806, 16.6299, 11.9750], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y * y * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1055e11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.6269, 5.5433, 3.9917], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eecb522",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a0e46b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([3.8089, 4.7088, 3.9958])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "# This z.backward() just computes the chain rule\n",
    "# and then x.grad is just the gradient \\nabla_x z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02d15464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0956,  0.3544, -0.0021], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2515e4e",
   "metadata": {},
   "source": [
    "This last line is dz/dx, where z(x) = mean(3 * ((x + 2)^2)). We can check this gave us the right answer: dz/dx is just \n",
    "\\begin{align*}\n",
    "    \\nabla_x z &= \\nabla_x \\frac{3 * [(x_1 + 2)^2 + (x_2 + 2)^2 + (x_3 + 2)^2]}{3} \\\\ \n",
    "    &= \\nabla_x  [(x_1 + 2)^2 + (x_2 + 2)^2 + (x_3 + 2)^2] \\\\ \n",
    "    &= 2*(x_1 + 2, x_2 + 2, x_3 + 2) \\\\ \n",
    "    &= 2x + (4, 4, 4).\n",
    "\\end{align*}\n",
    "One can plug in whatever random values were initialized for $x$ above and see the answers agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "927846b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to train a neural network to approximate a linear function\n",
    "# f(x) = 2*x\n",
    "\n",
    "X = torch.tensor([1,2,3,4,5,6,7,8], dtype=torch.float32)\n",
    "y = torch.tensor([2,4,6,8,10,12,14,16], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e9c787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f8d9915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "def loss(y, y_pred):\n",
    "    return ((y - y_pred)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1adccb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49af7f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5.0) = 0.000\n"
     ]
    }
   ],
   "source": [
    "print(f'Prediction before training: f({X_test}) = {forward(X_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d98569aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, weight: 1.020 and loss: 102.000\n",
      "Epoch 10, weight: 1.999 and loss: 0.000\n",
      "Epoch 20, weight: 2.000 and loss: 0.000\n",
      "Epoch 30, weight: 2.000 and loss: 0.000\n",
      "Epoch 40, weight: 2.000 and loss: 0.000\n",
      "Epoch 50, weight: 2.000 and loss: 0.000\n",
      "Epoch 60, weight: 2.000 and loss: 0.000\n",
      "Epoch 70, weight: 2.000 and loss: 0.000\n",
      "Epoch 80, weight: 2.000 and loss: 0.000\n",
      "Epoch 90, weight: 2.000 and loss: 0.000\n",
      "Result after training: f(5.0) = 10.0\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "learning_rate = 0.01 # how far we step along the -gradient\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # predict - do the forward pass with the current weights\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # calculate the loss\n",
    "    l = loss(y, y_pred)\n",
    "    \n",
    "    # calculate the gradient d loss / d weights\n",
    "    l.backward() # this automatically calculates and updates the gradient of loss w.r.t w\n",
    "    \n",
    "    # update the weights based on this\n",
    "    # gradient descent: reset w_new to be w_old - w.grad()*learning_rate\n",
    "    with torch.no_grad():\n",
    "        w = w - learning_rate*w.grad\n",
    "        \n",
    "    # empty the gradients after updating\n",
    "    w = w.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, weight: {w:.3f} and loss: {l:.3f}')\n",
    "        \n",
    "print(f'Result after training: f({X_test}) = {forward(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9db8db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ff61bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = w.data.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6968aa50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "070db83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb6ee7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training samples\n",
    "X = torch.tensor([[1], [2], [3], [4], [5], [6], [7], [8]], dtype=torch.float32)\n",
    "y = torch.tensor([[2], [4], [6], [8], [10], [12], [14], [16]], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0268a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd330386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 8\n",
      "Number of features: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\", n_samples)\n",
    "print(\"Number of features:\", n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a222baf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sample\n",
    "X_test = torch.tensor([5], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b8ad4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        # Define different layers (1 for linear regression)\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lin(x) # run x through the layers\n",
    "    \n",
    "    def dummy_function(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99153d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size, output_size = n_features, n_features\n",
    "    \n",
    "model = LinearRegression(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2ea5439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5.0) = 0.791\n"
     ]
    }
   ],
   "source": [
    "print(f'Prediction before training: f({X_test.item()}) = {model(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3f192a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, weight: 1.206202745437622, loss = 85.30561828613281\n",
      "Epoch: 10, weight: 2.0442826747894287, loss = 0.013176499865949154\n",
      "Epoch: 20, weight: 2.0430080890655518, loss = 0.01213756762444973\n",
      "Epoch: 30, weight: 2.0413217544555664, loss = 0.011204290203750134\n",
      "Epoch: 40, weight: 2.039701461791992, loss = 0.01034282986074686\n",
      "Epoch: 50, weight: 2.038144588470459, loss = 0.009547552093863487\n",
      "Epoch: 60, weight: 2.036648750305176, loss = 0.00881342962384224\n",
      "Epoch: 70, weight: 2.0352115631103516, loss = 0.008135775104165077\n",
      "Epoch: 80, weight: 2.0338308811187744, loss = 0.007510251831263304\n",
      "Epoch: 90, weight: 2.0325043201446533, loss = 0.006932767108082771\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "n_epochs = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Training loop \n",
    "for epoch in range(n_epochs):\n",
    "    # predict: forward pass\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # calculate loss\n",
    "    l = loss(y, y_pred)\n",
    "    \n",
    "    # calculate gradients\n",
    "    l.backward()\n",
    "    \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # empty gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        w, b = model.parameters() # unpack parameters\n",
    "        print(f'Epoch: {epoch}, weight: {w[0][0].item()}, loss = {l.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "013e7077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction after training: f(5.0) = 9.980487823486328\n"
     ]
    }
   ],
   "source": [
    "print(f'Prediction after training: f({X_test.item()}) = {model(X_test).item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c347f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c0f6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a62cd368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1ead9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 500\n",
    "num_classes = 10 \n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6c50d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f7d6078",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                                          train=False,\n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2b89998",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85d9605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = iter(train_loader)\n",
    "\n",
    "example_data, example_targets = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c00b1a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0,6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray_r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5aaeb43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b96e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02f9be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7be07563",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total_steps = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd749724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2, Step 0/600, Loss 2.3068\n",
      "Epoch 0/2, Step 100/600, Loss 0.2874\n",
      "Epoch 0/2, Step 200/600, Loss 0.1771\n",
      "Epoch 0/2, Step 300/600, Loss 0.1106\n",
      "Epoch 0/2, Step 400/600, Loss 0.1572\n",
      "Epoch 0/2, Step 500/600, Loss 0.0952\n",
      "Epoch 1/2, Step 0/600, Loss 0.2483\n",
      "Epoch 1/2, Step 100/600, Loss 0.1133\n",
      "Epoch 1/2, Step 200/600, Loss 0.0914\n",
      "Epoch 1/2, Step 300/600, Loss 0.0789\n",
      "Epoch 1/2, Step 400/600, Loss 0.0605\n",
      "Epoch 1/2, Step 500/600, Loss 0.0662\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # origin shape = [100, 1, 28, 28]\n",
    "        # resized = [100, 784]\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward pass, loss calculation\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backwards and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch {epoch}/{num_epochs}, Step {i}/{n_total_steps}, Loss {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "701fe019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of trained model: 0.9695\n"
     ]
    }
   ],
   "source": [
    "# Don't need gradients for prediction\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = len(test_loader.dataset)\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        # max returns max value, index\n",
    "        _, predicted = torch.max(outputs,1)\n",
    "        n_correct += (predicted==labels).sum().item()\n",
    "    \n",
    "    acc = n_correct/n_samples\n",
    "\n",
    "print(f'Accuracy of trained model: {acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
