{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76946215",
   "metadata": {},
   "source": [
    "# Linear Regression using Tensorflow\n",
    "\n",
    "In this notebook, we make a custom loss funtion for tensor flow, then do a linear regression on our features for various optimizers (mostly Adam, after preliminary testing) in tensor flow models.\n",
    "\n",
    "Result: The best linear regression gives an mae of 1.210 on k-fold validation and uses the following features: \n",
    "-az_t_pred\n",
    "-ze_t_pred\n",
    "-low_cluster (cutoff of 2)\n",
    "-high_cluster (cutoff of 9)\n",
    "-mse_cat (cutoff of 721)\n",
    "-x_skew (cutoff of .9)\n",
    "-y_skew\n",
    "-z_skew\n",
    "It also uses the Adam optimizer and 9 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48542ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\k_vsl\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e41db2",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76344939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function\n",
    "def get_mae(az_true, zen_true, az_pred, zen_pred): \n",
    "    \"\"\"\n",
    "    Given a predicted and true azimuth and zenith, compute the mae (mean angular error)\n",
    "    \"\"\"    \n",
    "    \n",
    "    # pre-compute all sine and cosine values\n",
    "    sa1 = tf.math.sin(az_true)\n",
    "    ca1 = tf.math.cos(az_true)\n",
    "    sz1 = tf.math.sin(zen_true)\n",
    "    cz1 = tf.math.cos(zen_true)\n",
    "    \n",
    "    sa2 = tf.math.sin(az_pred)\n",
    "    ca2 = tf.math.cos(az_pred)\n",
    "    sz2 = tf.math.sin(zen_pred)\n",
    "    cz2 = tf.math.cos(zen_pred)\n",
    "    \n",
    "    # scalar product of the two cartesian vectors (x = sz*ca, y = sz*sa, z = cz)\n",
    "    scalar_prod = sz1*sz2*(ca1*ca2 + sa1*sa2) + (cz1*cz2)\n",
    "    \n",
    "    # scalar product of two unit vectors is always between -1 and 1, this is against nummerical instability\n",
    "    # that might otherwise occure from the finite precision of the sine and cosine functions\n",
    "    scalar_prod = tf.clip_by_value(scalar_prod, -1.0, 1.0)\n",
    "    \n",
    "    # convert back to an angle (in radian)\n",
    "    return tf.reduce_mean(tf.abs(tf.acos(scalar_prod)))\n",
    "\n",
    "def mae(y_true, y_pred): \n",
    "    #return tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "    #print(type(y_true))\n",
    "    ta = tf.gather(y_true, 0)\n",
    "    tz = tf.gather(y_true, 1)\n",
    "    pa = tf.gather(y_pred, 0)\n",
    "    pz = tf.gather(y_pred, 1)\n",
    "    return get_mae(ta, tz, pa, pz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e6771",
   "metadata": {},
   "source": [
    "# Set up train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c9532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "event_data = pd.read_csv(\"C:/Users/k_vsl/Documents/Erdos/Boot Camp/ice-cube-katja/features-final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9c5b934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k_vsl\\AppData\\Local\\Temp\\ipykernel_10980\\586390680.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  V['x_skew'] = [(val > .9) for val in V.per_x]\n",
      "C:\\Users\\k_vsl\\AppData\\Local\\Temp\\ipykernel_10980\\586390680.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  V['y_skew'] = [(val > .9) for val in V.per_y]\n",
      "C:\\Users\\k_vsl\\AppData\\Local\\Temp\\ipykernel_10980\\586390680.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  V['z_skew'] = [(val > .9) for val in V.per_z]\n",
      "C:\\Users\\k_vsl\\AppData\\Local\\Temp\\ipykernel_10980\\586390680.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  V['low_cluster'] = [(c < 2) for c in V.num_clusters]\n",
      "C:\\Users\\k_vsl\\AppData\\Local\\Temp\\ipykernel_10980\\586390680.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  V['high_cluster'] = [(c > 9) for c in V.num_clusters]\n",
      "C:\\Users\\k_vsl\\AppData\\Local\\Temp\\ipykernel_10980\\586390680.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  V.replace({False: 0, True: 1}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# X contains all categorical variables with cutoff of .5 for skew\n",
    "# V contains a subset of categorical variables, where skew has a cutoff of .9 and we categorize into low, medium, and high clusters\n",
    "X = event_data\n",
    "X = X.set_index(\"event_id\")\n",
    "y = event_data[['event_id', 'az_true', 'ze_true']]\n",
    "y = y.set_index(\"event_id\")\n",
    "X = X[['az_t_pred', 'ze_t_pred', 'cat_x', 'cat_y', 'cat_z', 'mse_cat', 'cat_1.0',\n",
    "       'cat_2.0', 'cat_3.0', 'cat_4.0', 'cat_5.0', 'cat_6.0', 'cat_7.0',\n",
    "       'cat_8.0', 'cat_9.0', 'cat_10.0']]\n",
    "V = event_data[['az_t_pred', 'ze_t_pred', 'num_clusters','mse_cat','per_x', 'per_y', 'per_z']]\n",
    "V['x_skew'] = [(val > .9) for val in V.per_x]\n",
    "V['y_skew'] = [(val > .9) for val in V.per_y]\n",
    "V['z_skew'] = [(val > .9) for val in V.per_z]\n",
    "V['low_cluster'] = [(c < 2) for c in V.num_clusters]\n",
    "V['high_cluster'] = [(c > 9) for c in V.num_clusters]\n",
    "V.replace({False: 0, True: 1}, inplace=True)\n",
    "w = y\n",
    "V = V[['az_t_pred', 'ze_t_pred', 'mse_cat', 'x_skew', 'y_skew', 'z_skew', 'low_cluster', 'high_cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a06a2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate train and test\n",
    "\n",
    "# Separate out a final training set\n",
    "# random seed = 134\n",
    "# test size = 25%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                             shuffle = True,\n",
    "                                                             random_state = 134, \n",
    "                                                             test_size = .25)\n",
    "V_train, V_test, w_train, w_test = train_test_split(V, w, \n",
    "                                                             shuffle = True,\n",
    "                                                             random_state = 134, \n",
    "                                                             test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c28cea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross validation\n",
    "# this cell imitates the erdos lectures notes on kfold cross validation , k = 5\n",
    "# random seed to all splits random_seed = 134\n",
    "kfold = KFold(n_splits = 5,\n",
    "             shuffle = True,\n",
    "             random_state = 134)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb4054",
   "metadata": {},
   "source": [
    "# Helper training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb7bc6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which runs through optimizers, various epochs, kfold validation\n",
    "def tensor_train(X,  y, optimizers, shape, epochs): \n",
    "    n = len(optimizers)\n",
    "    losses = np.zeros((n,10,5))\n",
    "    i = 0\n",
    "    for opt in optimizers: \n",
    "        print(\"Trying Optimizer \" + str(opt))\n",
    "        k = 0\n",
    "        for train_index, test_index in kfold.split(X, y):\n",
    "                    \n",
    "            ## get the kfold training data\n",
    "            X_train = X.iloc[train_index,:]\n",
    "            y_train = y.iloc[train_index]\n",
    "\n",
    "            ## get the holdout data\n",
    "            X_holdout = X.iloc[test_index,:]\n",
    "            y_holdout = y.iloc[test_index]\n",
    "                    \n",
    "            j = 0\n",
    "            for e in epochs: \n",
    "\n",
    "                ## Fit the data\n",
    "                model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(shape,))])\n",
    "                model.compile(optimizer = opt, loss = mae)\n",
    "                model.fit(X_train, y_train, epochs=e)\n",
    "                loss = model.evaluate(X_holdout, y_holdout)\n",
    "\n",
    "                losses[i][j][k] = loss\n",
    "                j += 1\n",
    "                    \n",
    "            k += 1\n",
    "        \n",
    "        i += 1\n",
    "            \n",
    "    return losses\n",
    "\n",
    "# Function which tests one optimizer with a given number of epochs\n",
    "def tensor_train_spec(X,y, opt, shape, epoch):\n",
    "    losses = np.zeros(5)\n",
    "    i = 0\n",
    "    for train_index, test_index in kfold.split(X, y):\n",
    "        ## get the kfold training data\n",
    "        X_train = X.iloc[train_index,:]\n",
    "        y_train = y.iloc[train_index]\n",
    "\n",
    "        ## get the holdout data\n",
    "        X_holdout = X.iloc[test_index,:]\n",
    "        y_holdout = y.iloc[test_index]\n",
    "        model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(shape,))])\n",
    "        model.compile(optimizer = opt, loss = mae)\n",
    "        model.fit(X_train, y_train, epochs=epoch)\n",
    "        loss = model.evaluate(X_holdout, y_holdout)\n",
    "        losses[i] = loss\n",
    "        i +=1\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96044308",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5ed0d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying Optimizer Adam\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2365\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 18s 5ms/step - loss: 1.2094\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 17s 4ms/step - loss: 1.2129\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 17s 5ms/step - loss: 1.1990\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.1998\n",
      "938/938 [==============================] - 4s 3ms/step - loss: 1.2057\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 14s 3ms/step - loss: 1.3949\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.2326\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.2264\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2159\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2241\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2260\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2172\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.2226\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 13s 4ms/step - loss: 1.2062\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.2157\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.2154\n",
      "Epoch 1/15\n",
      "3750/3750 [==============================] - 19s 4ms/step - loss: 1.4224\n",
      "Epoch 2/15\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.2489\n",
      "Epoch 3/15\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2196\n",
      "Epoch 4/15\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.2201\n",
      "Epoch 5/15\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2155\n",
      "Epoch 6/15\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.2230\n",
      "Epoch 7/15\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2174\n",
      "Epoch 8/15\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.2136\n",
      "Epoch 9/15\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2258\n",
      "Epoch 10/15\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2122\n",
      "Epoch 11/15\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2158\n",
      "Epoch 12/15\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.2160\n",
      "Epoch 13/15\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2256\n",
      "Epoch 14/15\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.2194\n",
      "Epoch 15/15\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.2099\n",
      "938/938 [==============================] - 4s 3ms/step - loss: 1.2192\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.2463\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.2261\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2100\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.2094\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.2142\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.1918\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 18s 4ms/step - loss: 1.2885\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2185\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 24s 6ms/step - loss: 1.2092\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2079\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2064\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2044\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.2037\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.1989\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.1973\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2047\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.1910\n",
      "Epoch 1/15\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.3009\n",
      "Epoch 2/15\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.2383\n",
      "Epoch 3/15\n",
      "3750/3750 [==============================] - 20s 5ms/step - loss: 1.2182\n",
      "Epoch 4/15\n",
      "3750/3750 [==============================] - 21s 6ms/step - loss: 1.2294\n",
      "Epoch 5/15\n",
      "3750/3750 [==============================] - 20s 5ms/step - loss: 1.2170\n",
      "Epoch 6/15\n",
      "3750/3750 [==============================] - 18s 5ms/step - loss: 1.2193\n",
      "Epoch 7/15\n",
      "3750/3750 [==============================] - 17s 5ms/step - loss: 1.2114\n",
      "Epoch 8/15\n",
      "3750/3750 [==============================] - 17s 5ms/step - loss: 1.2264\n",
      "Epoch 9/15\n",
      "3750/3750 [==============================] - 23s 6ms/step - loss: 1.2200\n",
      "Epoch 10/15\n",
      "3750/3750 [==============================] - 21s 6ms/step - loss: 1.2145\n",
      "Epoch 11/15\n",
      "3750/3750 [==============================] - 18s 5ms/step - loss: 1.2173\n",
      "Epoch 12/15\n",
      "3750/3750 [==============================] - 17s 5ms/step - loss: 1.2122\n",
      "Epoch 13/15\n",
      "3750/3750 [==============================] - 18s 5ms/step - loss: 1.2234\n",
      "Epoch 14/15\n",
      "3750/3750 [==============================] - 24s 6ms/step - loss: 1.2230\n",
      "Epoch 15/15\n",
      "3750/3750 [==============================] - 22s 6ms/step - loss: 1.2099\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.2024\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 24s 6ms/step - loss: 1.2942\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 24s 6ms/step - loss: 1.2434\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 19s 5ms/step - loss: 1.2190\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 18s 5ms/step - loss: 1.2282\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 22s 6ms/step - loss: 1.2181\n",
      "938/938 [==============================] - 5s 4ms/step - loss: 1.2322\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 23s 5ms/step - loss: 1.2789\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 32s 9ms/step - loss: 1.2192\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 20s 5ms/step - loss: 1.2122\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.2001\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.2059\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 20s 5ms/step - loss: 1.2133\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 24s 6ms/step - loss: 1.2074\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 17s 5ms/step - loss: 1.2055\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.1967\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 19s 5ms/step - loss: 1.2106\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 1.2111\n",
      "Epoch 1/15\n",
      "3750/3750 [==============================] - 38s 9ms/step - loss: 1.2603\n",
      "Epoch 2/15\n",
      "3750/3750 [==============================] - 18s 5ms/step - loss: 1.2143\n",
      "Epoch 3/15\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.2097\n",
      "Epoch 4/15\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2009\n",
      "Epoch 5/15\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2016\n",
      "Epoch 6/15\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.2066\n",
      "Epoch 7/15\n",
      "3750/3750 [==============================] - 19s 5ms/step - loss: 1.2104\n",
      "Epoch 8/15\n",
      "3750/3750 [==============================] - 19s 5ms/step - loss: 1.1894\n",
      "Epoch 9/15\n",
      "3750/3750 [==============================] - 36s 10ms/step - loss: 1.2083\n",
      "Epoch 10/15\n",
      "3750/3750 [==============================] - 22s 6ms/step - loss: 1.1983\n",
      "Epoch 11/15\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.2062\n",
      "Epoch 12/15\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.2065\n",
      "Epoch 13/15\n",
      "3750/3750 [==============================] - 17s 5ms/step - loss: 1.2073\n",
      "Epoch 14/15\n",
      "3750/3750 [==============================] - 23s 6ms/step - loss: 1.2045\n",
      "Epoch 15/15\n",
      "3750/3750 [==============================] - 20s 5ms/step - loss: 1.2013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 4s 4ms/step - loss: 1.2094\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 27s 7ms/step - loss: 1.2688\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 26s 7ms/step - loss: 1.2313\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 33s 9ms/step - loss: 1.2109\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2054\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2104\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.2066\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 17s 4ms/step - loss: 1.3152\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.2168\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 25s 7ms/step - loss: 1.2067\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 21s 6ms/step - loss: 1.2037\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 21s 6ms/step - loss: 1.2008\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 19s 5ms/step - loss: 1.1997\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 28s 7ms/step - loss: 1.2068\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 55s 15ms/step - loss: 1.2009\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 21s 6ms/step - loss: 1.2143\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 27s 7ms/step - loss: 1.1933\n",
      "938/938 [==============================] - 7s 6ms/step - loss: 1.2034\n",
      "Epoch 1/15\n",
      "3750/3750 [==============================] - 28s 7ms/step - loss: 1.3312\n",
      "Epoch 2/15\n",
      "3750/3750 [==============================] - 22s 6ms/step - loss: 1.2574\n",
      "Epoch 3/15\n",
      "3750/3750 [==============================] - 21s 6ms/step - loss: 1.2371\n",
      "Epoch 4/15\n",
      "3750/3750 [==============================] - 35s 9ms/step - loss: 1.2333\n",
      "Epoch 5/15\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 1.2214\n",
      "Epoch 6/15\n",
      "3750/3750 [==============================] - 29s 8ms/step - loss: 1.2175\n",
      "Epoch 7/15\n",
      "3750/3750 [==============================] - 17s 4ms/step - loss: 1.2102\n",
      "Epoch 8/15\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.2199\n",
      "Epoch 9/15\n",
      "3750/3750 [==============================] - 32s 8ms/step - loss: 1.2202\n",
      "Epoch 10/15\n",
      "3750/3750 [==============================] - 34s 9ms/step - loss: 1.2159\n",
      "Epoch 11/15\n",
      "3750/3750 [==============================] - 35s 9ms/step - loss: 1.2275\n",
      "Epoch 12/15\n",
      "3750/3750 [==============================] - 20s 5ms/step - loss: 1.2197\n",
      "Epoch 13/15\n",
      "3750/3750 [==============================] - 28s 8ms/step - loss: 1.2138\n",
      "Epoch 14/15\n",
      "3750/3750 [==============================] - 25s 7ms/step - loss: 1.2164\n",
      "Epoch 15/15\n",
      "3750/3750 [==============================] - 33s 9ms/step - loss: 1.2116\n",
      "938/938 [==============================] - 9s 8ms/step - loss: 1.2197\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 37s 8ms/step - loss: 1.3092\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 29s 8ms/step - loss: 1.2252\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 26s 7ms/step - loss: 1.2165\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 17s 5ms/step - loss: 1.2110\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 17s 5ms/step - loss: 1.2094\n",
      "938/938 [==============================] - 10s 9ms/step - loss: 1.2256\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 23s 5ms/step - loss: 1.3296\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 27s 7ms/step - loss: 1.2289\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 48s 13ms/step - loss: 1.2271\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 57s 15ms/step - loss: 1.2292\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 20s 5ms/step - loss: 1.2314\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.2101\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.2095\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 35s 9ms/step - loss: 1.2128\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 51s 14ms/step - loss: 1.2166\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 45s 12ms/step - loss: 1.2220\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.2395\n",
      "Epoch 1/15\n",
      "3750/3750 [==============================] - 27s 7ms/step - loss: 1.3414\n",
      "Epoch 2/15\n",
      "3750/3750 [==============================] - 19s 5ms/step - loss: 1.2337\n",
      "Epoch 3/15\n",
      "3750/3750 [==============================] - 24s 6ms/step - loss: 1.2036\n",
      "Epoch 4/15\n",
      "3750/3750 [==============================] - 62s 17ms/step - loss: 1.2074\n",
      "Epoch 5/15\n",
      "3750/3750 [==============================] - 45s 12ms/step - loss: 1.1970\n",
      "Epoch 6/15\n",
      "3750/3750 [==============================] - 20s 5ms/step - loss: 1.2003\n",
      "Epoch 7/15\n",
      "3750/3750 [==============================] - 35s 9ms/step - loss: 1.2096\n",
      "Epoch 8/15\n",
      "3750/3750 [==============================] - 18s 5ms/step - loss: 1.1960\n",
      "Epoch 9/15\n",
      "3750/3750 [==============================] - 20s 5ms/step - loss: 1.1999\n",
      "Epoch 10/15\n",
      "3750/3750 [==============================] - 21s 6ms/step - loss: 1.2092\n",
      "Epoch 11/15\n",
      "3750/3750 [==============================] - 67s 18ms/step - loss: 1.1924\n",
      "Epoch 12/15\n",
      "3750/3750 [==============================] - 27s 7ms/step - loss: 1.2078\n",
      "Epoch 13/15\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2130\n",
      "Epoch 14/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2065\n",
      "Epoch 15/15\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 1.2084\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.2290\n",
      "Trying Optimizer Adadelta\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 24s 6ms/step - loss: 1.4588\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 54s 14ms/step - loss: 1.4554\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 30s 8ms/step - loss: 1.4638\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 23s 6ms/step - loss: 1.4634\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 17s 5ms/step - loss: 1.4595\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.4685\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 21s 5ms/step - loss: 1.4788\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 19s 5ms/step - loss: 1.5105\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.4985\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.4991\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 24s 6ms/step - loss: 1.4829\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 59s 16ms/step - loss: 1.4959\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 23s 6ms/step - loss: 1.4891\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.4793\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.4977\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.4759\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.4826\n",
      "Epoch 1/15\n",
      "3750/3750 [==============================] - 24s 6ms/step - loss: 1.4812\n",
      "Epoch 2/15\n",
      "3750/3750 [==============================] - 64s 17ms/step - loss: 1.4882\n",
      "Epoch 3/15\n",
      "3750/3750 [==============================] - 25s 7ms/step - loss: 1.4669\n",
      "Epoch 4/15\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.4820\n",
      "Epoch 5/15\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.4792\n",
      "Epoch 6/15\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.4739\n",
      "Epoch 7/15\n",
      "3750/3750 [==============================] - 13s 4ms/step - loss: 1.4865\n",
      "Epoch 8/15\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.4655\n",
      "Epoch 9/15\n",
      "3750/3750 [==============================] - 27s 7ms/step - loss: 1.4845\n",
      "Epoch 10/15\n",
      "3750/3750 [==============================] - 68s 18ms/step - loss: 1.4822\n",
      "Epoch 11/15\n",
      "3750/3750 [==============================] - 21s 6ms/step - loss: 1.4739\n",
      "Epoch 12/15\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.4703\n",
      "Epoch 13/15\n",
      "3750/3750 [==============================] - 13s 4ms/step - loss: 1.4871\n",
      "Epoch 14/15\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.4821\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.4795\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4584\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 17s 4ms/step - loss: 1.5007\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 26s 7ms/step - loss: 1.4839\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 55s 15ms/step - loss: 1.4895\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 20s 5ms/step - loss: 1.4806\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 18s 5ms/step - loss: 1.4819\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.4602\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 14s 3ms/step - loss: 1.4142\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.4129\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.4114\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.4064\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.4104\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.3856\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.3952\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.3950\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 1.3798\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 13s 4ms/step - loss: 1.3925\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.3892\n",
      "Epoch 1/15\n",
      "3750/3750 [==============================] - 17s 4ms/step - loss: 1.4073\n",
      "Epoch 2/15\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.4276\n",
      "Epoch 3/15\n",
      "3750/3750 [==============================] - 34s 9ms/step - loss: 1.4135\n",
      "Epoch 4/15\n",
      "3750/3750 [==============================] - 26s 7ms/step - loss: 1.4164\n",
      "Epoch 5/15\n",
      "3750/3750 [==============================] - 13s 4ms/step - loss: 1.4213\n",
      "Epoch 6/15\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 1.4177\n",
      "Epoch 7/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.4210\n",
      "Epoch 8/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.4249\n",
      "Epoch 9/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.3998\n",
      "Epoch 10/15\n",
      "3750/3750 [==============================] - 9s 3ms/step - loss: 1.4055\n",
      "Epoch 11/15\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 1.4011\n",
      "Epoch 12/15\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.4019\n",
      "Epoch 13/15\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.4114\n",
      "Epoch 14/15\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.4178\n",
      "Epoch 15/15\n",
      "3750/3750 [==============================] - 33s 9ms/step - loss: 1.3899\n",
      "938/938 [==============================] - 7s 6ms/step - loss: 1.3849\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 19s 4ms/step - loss: 1.4698\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 19s 5ms/step - loss: 1.4791\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.4580\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 1.4834\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.4705\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.4638\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.4591\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.4665\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 13s 4ms/step - loss: 1.4583\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.4734\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.4657\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.4616\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.4726\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 26s 7ms/step - loss: 1.4646\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 19s 5ms/step - loss: 1.4688\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.4588\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4533\n",
      "Epoch 1/15\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 1.4786\n",
      "Epoch 2/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.4691\n",
      "Epoch 3/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.4825\n",
      "Epoch 4/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.4658\n",
      "Epoch 5/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.4795\n",
      "Epoch 6/15\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 1.4731\n",
      "Epoch 7/15\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 1.4706\n",
      "Epoch 8/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.4668\n",
      "Epoch 9/15\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.4786\n",
      "Epoch 10/15\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.4649\n",
      "Epoch 11/15\n",
      "3750/3750 [==============================] - 39s 10ms/step - loss: 1.4429\n",
      "Epoch 12/15\n",
      "3750/3750 [==============================] - 18s 5ms/step - loss: 1.4521\n",
      "Epoch 13/15\n",
      "3750/3750 [==============================] - 13s 4ms/step - loss: 1.4613\n",
      "Epoch 14/15\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 1.4799\n",
      "Epoch 15/15\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 1.4760\n",
      "938/938 [==============================] - 5s 3ms/step - loss: 1.4504\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 1.5216\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.5344\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.5178\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.5336\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 18s 5ms/step - loss: 1.5466\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 1.5520\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 29s 7ms/step - loss: 1.4721\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 18s 5ms/step - loss: 1.4972\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.4734\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.4690\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.4692\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 1.4692\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 1.4614\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.4699\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.4689\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 24s 6ms/step - loss: 1.4746\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 1.4762\n",
      "Epoch 1/15\n",
      "3750/3750 [==============================] - 38s 9ms/step - loss: 1.5703\n",
      "Epoch 2/15\n",
      "3750/3750 [==============================] - 19s 5ms/step - loss: 1.5652\n",
      "Epoch 3/15\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.5480\n",
      "Epoch 4/15\n",
      "3750/3750 [==============================] - 13s 4ms/step - loss: 1.5821\n",
      "Epoch 5/15\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.5645\n",
      "Epoch 6/15\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.5708\n",
      "Epoch 7/15\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 1.5683\n",
      "Epoch 8/15\n",
      "3750/3750 [==============================] - 13s 4ms/step - loss: 1.5750\n",
      "Epoch 9/15\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.5738\n",
      "Epoch 10/15\n",
      "3750/3750 [==============================] - 27s 7ms/step - loss: 1.5543\n",
      "Epoch 11/15\n",
      "3750/3750 [==============================] - 51s 14ms/step - loss: 1.5720\n",
      "Epoch 12/15\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.5590\n",
      "Epoch 13/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.5772\n",
      "Epoch 14/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.5696\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.5741\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.5905\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 10s 2ms/step - loss: 1.4527\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 1.4669\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.4686\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.4545\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.4560\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.4584\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 1.4618\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.4686\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.4599\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 21s 6ms/step - loss: 1.4504\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.4694\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 1.4648\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.4533\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.4683\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.4620\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.4678\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.4551\n",
      "Epoch 1/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.4043\n",
      "Epoch 2/15\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.3883\n",
      "Epoch 3/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.3924\n",
      "Epoch 4/15\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.3978\n",
      "Epoch 5/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.4021\n",
      "Epoch 6/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.3883\n",
      "Epoch 7/15\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.3936\n",
      "Epoch 8/15\n",
      "3750/3750 [==============================] - 17s 5ms/step - loss: 1.4144\n",
      "Epoch 9/15\n",
      "3750/3750 [==============================] - 21s 6ms/step - loss: 1.3903\n",
      "Epoch 10/15\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.3735\n",
      "Epoch 11/15\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 1.4030\n",
      "Epoch 12/15\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 1.4024\n",
      "Epoch 13/15\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 1.3950\n",
      "Epoch 14/15\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 1.3885\n",
      "Epoch 15/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.3984\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.3829\n",
      "Trying Optimizer sgd\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 10s 2ms/step - loss: 1.2405\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 1.2178\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 1.2227\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 1.2249\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 12s 3ms/step - loss: 1.2116\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.2186\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 14s 4ms/step - loss: 1.2604\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 17s 5ms/step - loss: 1.2387\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 35s 9ms/step - loss: 1.2387\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 26s 7ms/step - loss: 1.2287\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 15s 4ms/step - loss: 1.2339\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 1.2305\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 1.2374\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2462\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2441\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2389\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.2292\n",
      "Epoch 1/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2741\n",
      "Epoch 2/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2413\n",
      "Epoch 3/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2359\n",
      "Epoch 4/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2372\n",
      "Epoch 5/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2361\n",
      "Epoch 6/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2381\n",
      "Epoch 7/15\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2436\n",
      "Epoch 8/15\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2413\n",
      "Epoch 9/15\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2296\n",
      "Epoch 10/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2455\n",
      "Epoch 11/15\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2343\n",
      "Epoch 12/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2423\n",
      "Epoch 13/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2322\n",
      "Epoch 14/15\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 1.2302\n",
      "Epoch 15/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2358\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 1.2293\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2283\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2250\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2253\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2142\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2187\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.2004\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2341\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2267\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2309\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2300\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2236\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2283\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2230\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2286\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2275\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2171\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.2029\n",
      "Epoch 1/15\n",
      "3750/3750 [==============================] - 10s 2ms/step - loss: 1.2458\n",
      "Epoch 2/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2315\n",
      "Epoch 3/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2237\n",
      "Epoch 4/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2259\n",
      "Epoch 5/15\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 1.2260\n",
      "Epoch 6/15\n",
      "3750/3750 [==============================] - 13s 3ms/step - loss: 1.2245\n",
      "Epoch 7/15\n",
      "3750/3750 [==============================] - 16s 4ms/step - loss: 1.2237\n",
      "Epoch 8/15\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2295\n",
      "Epoch 9/15\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2206\n",
      "Epoch 10/15\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 1.2384\n",
      "Epoch 11/15\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 1.2276\n",
      "Epoch 12/15\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2305\n",
      "Epoch 13/15\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 1.2268\n",
      "Epoch 14/15\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2326\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2273\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.1904\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2653\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2260\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 1.2349\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2471\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 1.2448\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 1.2436\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 6s 1ms/step - loss: 1.2620\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2291\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 1.2381\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 6s 1ms/step - loss: 1.2352\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2346\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 1.2360\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2332\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 6s 1ms/step - loss: 1.2382\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 1.2429\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2372\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 1.2643\n",
      "Epoch 1/15\n",
      "3750/3750 [==============================] - 6s 1ms/step - loss: 1.2587\n",
      "Epoch 2/15\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2421\n",
      "Epoch 3/15\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2324\n",
      "Epoch 4/15\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2350\n",
      "Epoch 5/15\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2280\n",
      "Epoch 6/15\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2430\n",
      "Epoch 7/15\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2349\n",
      "Epoch 8/15\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2404\n",
      "Epoch 9/15\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2424\n",
      "Epoch 10/15\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2268\n",
      "Epoch 11/15\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2395\n",
      "Epoch 12/15\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2457\n",
      "Epoch 13/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2393\n",
      "Epoch 14/15\n",
      "3750/3750 [==============================] - 6s 2ms/step - loss: 1.2432\n",
      "Epoch 15/15\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2323\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.2703\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2463\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2275\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2272\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2237\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2246\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.2693\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2497\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2265\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2298\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 1.2288\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2202\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 10s 3ms/step - loss: 1.2304\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2363\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2219\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2274\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2290\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.2193\n",
      "Epoch 1/15\n",
      "3750/3750 [==============================] - 10s 2ms/step - loss: 1.2585\n",
      "Epoch 2/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2180\n",
      "Epoch 3/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2300\n",
      "Epoch 4/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2101\n",
      "Epoch 5/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2280\n",
      "Epoch 6/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2244\n",
      "Epoch 7/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2194\n",
      "Epoch 8/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2411\n",
      "Epoch 9/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2294\n",
      "Epoch 10/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2083\n",
      "Epoch 11/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2116\n",
      "Epoch 12/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2229\n",
      "Epoch 13/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2292\n",
      "Epoch 14/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2321\n",
      "Epoch 15/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2377\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.2279\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2405\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2245\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2217\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2239\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2401\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.2360\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 10s 2ms/step - loss: 1.2364\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2285\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2207\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2326\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2247\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2237\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2217\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2311\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2256\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2118\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.2291\n",
      "Epoch 1/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2513\n",
      "Epoch 2/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2284\n",
      "Epoch 3/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2423\n",
      "Epoch 4/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2348\n",
      "Epoch 5/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2355\n",
      "Epoch 6/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2350\n",
      "Epoch 7/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2362\n",
      "Epoch 8/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2367\n",
      "Epoch 9/15\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.2390\n",
      "Epoch 10/15\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2337\n",
      "Epoch 11/15\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2348\n",
      "Epoch 12/15\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2281\n",
      "Epoch 13/15\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 1.2435\n",
      "Epoch 14/15\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.2339\n",
      "Epoch 15/15\n",
      "3750/3750 [==============================] - 11s 3ms/step - loss: 1.2360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 3s 3ms/step - loss: 1.2483\n"
     ]
    }
   ],
   "source": [
    "# Look at X\n",
    "epochs = [5,10,15]\n",
    "optimizers = ['Adam', 'Adadelta','sgd']\n",
    "losses = tensor_train(X_train, y_train, optimizers, 16, epochs)\n",
    "n = len(optimizers)\n",
    "m = len(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fabf0742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.21238358, 1.21209829, 1.21595223],\n",
       "       [1.48057373, 1.45127573, 1.45340931],\n",
       "       [1.23358357, 1.22896423, 1.23320155]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(optimizers)\n",
    "m = len(epochs)\n",
    "means = np.zeros((n,m))\n",
    "for i in range(0,n): \n",
    "    for j in range(0,m): \n",
    "        means[i][j] = losses[i][j].mean()\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bfe5d8",
   "metadata": {},
   "source": [
    "Conclusion: \n",
    "    Adam got MAE: 1.212, 1.212, 1.216\n",
    "    Adadelta MAE: 1.481, 1.451, 1.453\n",
    "    sgd MAE: 1.233, 1.229, 1.233\n",
    "    Adam is the best optimizer to use for our scenario. \n",
    "    We may want to cut down on the number of categorical variables to prevent overfitting...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2016548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at V\n",
    "epochs = [6,9, 13,26]\n",
    "optimizers = ['Adam']\n",
    "mae = np.zeros(len(epochs))\n",
    "i = 0\n",
    "for e in epochs: \n",
    "    loss = tensor_train_spec(V_train,w_train, 'Adam', 8, e)\n",
    "    print(loss)\n",
    "    print(loss.mean())\n",
    "    mae[i] = loss.mean()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abce8315",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result: 9 epochs appears to be the best\n",
    "    \n",
    "6 epochs: 1.2728947401046753\n",
    "9 epochs: 1.2104717016220092\n",
    "13 epochs: 1.2120121955871581\n",
    "26 epochs: 1.265834665298462"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb2aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate learning rate\n",
    "# Didn't end up doing this fully as preliminary results were not positive\n",
    "decay_steps = 1000\n",
    "initial_learning_rate = .0001\n",
    "lr_schedule = keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate, decay_steps, warmup_target= None,\n",
    "    warmup_steps=0\n",
    ")\n",
    "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "loss = tensor_train_spec(V_train,w_train, opt, 8, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee47e67",
   "metadata": {},
   "source": [
    "# Test final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6080fb1",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f895cc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "4688/4688 [==============================] - 26s 5ms/step - loss: 1.2711\n",
      "Epoch 2/9\n",
      "4688/4688 [==============================] - 17s 4ms/step - loss: 1.2242\n",
      "Epoch 3/9\n",
      "4688/4688 [==============================] - 13s 3ms/step - loss: 1.2086\n",
      "Epoch 4/9\n",
      "4688/4688 [==============================] - 14s 3ms/step - loss: 1.2077\n",
      "Epoch 5/9\n",
      "4688/4688 [==============================] - 16s 3ms/step - loss: 1.2022\n",
      "Epoch 6/9\n",
      "4688/4688 [==============================] - 15s 3ms/step - loss: 1.2090\n",
      "Epoch 7/9\n",
      "4688/4688 [==============================] - 13s 3ms/step - loss: 1.2050\n",
      "Epoch 8/9\n",
      "4688/4688 [==============================] - 15s 3ms/step - loss: 1.2001\n",
      "Epoch 9/9\n",
      "4688/4688 [==============================] - 16s 3ms/step - loss: 1.1946\n",
      "1563/1563 [==============================] - 6s 3ms/step - loss: 1.2032\n"
     ]
    }
   ],
   "source": [
    "# Run the best model on testing data\n",
    "# epoch = 9, opt = Adam\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(8,))])\n",
    "model.compile(optimizer = 'Adam', loss = mae)\n",
    "model.fit(V_train, w_train, epochs=9)\n",
    "loss = model.evaluate(V_test, w_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e86a45ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.203155755996704"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad568f34",
   "metadata": {},
   "source": [
    "Testing our best model with our test data yields an MAE of 1.203"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
