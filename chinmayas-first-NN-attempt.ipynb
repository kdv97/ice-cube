{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2231cfc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "932d01a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m num_min_total_repeats \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     unique_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m      6\u001b[0m     pulses \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(df\u001b[38;5;241m.\u001b[39mloc[unique_indices[i]])\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(pulses[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39munique(pulses[:,\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m num_min_total_repeats):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Finds events with multiple pulses at the same sensors\n",
    "# here we ask for at least num_min_total_repeats repetitions\n",
    "num_min_total_repeats = 10\n",
    "for i in range(1000):\n",
    "    unique_indices = np.unique(df.index)\n",
    "    pulses = np.array(df.loc[unique_indices[i]])\n",
    "    if(pulses[:,0].shape[0] - np.unique(pulses[:,0]).shape[0] >= num_min_total_repeats):\n",
    "        print(unique_indices[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bd97c10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Without considerations for the auxiliary label and no explicit features consisting of sensor geometry\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Class for a dataset generated from a dataframe and data from the sensor geometry file\n",
    "class NeutrinoDataset(Dataset):\n",
    "    def __init__(self, batch_df, sg):\n",
    "        self.sensor_geom = sg\n",
    "        self.dataframe = batch_df\n",
    "        sensor_loc = np.array(sg.iloc[:])[:, 1:]\n",
    "        self.num_features = 5160*3\n",
    "        self.num_events = batch_df.index.nunique()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_events\n",
    "    \n",
    "    # Replaces sensor ID with sensor coordinates \n",
    "    def __getitem__(self, i):\n",
    "        df = self.dataframe\n",
    "        sg = self.sensor_geom\n",
    "        pulse_array = np.array(df.loc[df.index[i]])\n",
    "        pulse_array_sensors = np.concatenate((np.expand_dims(np.arange(5160), axis=1), np.zeros([5160, 3])), 1)\n",
    "\n",
    "        for pulse in pulse_array:\n",
    "            if(pulse_array_sensors[pulse[0]][1] == 0):\n",
    "                pulse_array_sensors[pulse[0]][1] = pulse[1] # first time\n",
    "            else:\n",
    "                # possible last time, will be the last time for the actual last one\n",
    "                pulse_array_sensors[pulse[0]][2] = pulse[1] \n",
    "            # Add charge\n",
    "            pulse_array_sensors[pulse[0]][3] += pulse[2]\n",
    "                \n",
    "        return np.ndarray.flatten(pulse_array_sensors[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "864253e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu121\n",
      "NNPredictor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=15480, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      "  (layer_norms): ModuleList()\n",
      "  (classifier): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "\n",
    "#Chinmaya Directories\n",
    "# sg = pd.read_csv('sensor_geometry.csv')\n",
    "# batch_df = pd.read_parquet('batch_104.parquet')\n",
    "\n",
    "sg=pd.read_csv('/opt/app/data/erdos-data/sensor_geometry.csv')\n",
    "batch_df=pd.read_parquet('/opt/app/data/erdos-data/train/batch_1.parquet')\n",
    "\n",
    "dataset = NeutrinoDataset(batch_df, sg)\n",
    "\n",
    "class NNPredictor(torch.nn.Module):\n",
    "    def __init__(self, use_activation = 'relu'):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layer_norms = nn.ModuleList()\n",
    "    \n",
    "        self.layers.append(nn.Linear(dataset.num_features, 100))\n",
    "        self.layers.append(nn.Linear(100, 50))\n",
    "        self.layers.append(nn.Linear(50, 10))\n",
    "        self.classifier = (nn.Linear(10,1))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        new_x = x\n",
    "        if(use_activation):\n",
    "            for layer in self.layers:\n",
    "                new_x = layer(new_x)\n",
    "                new_x = nn.ReLU()(new_x)\n",
    "        else:\n",
    "            for layer in self.layers:\n",
    "                new_x = layer(new_x)\n",
    "        \n",
    "        # Apply a final (linear) classifier.\n",
    "\n",
    "        return self.classifier(new_x)\n",
    "\n",
    "model = NNPredictor()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4461540",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2127d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
