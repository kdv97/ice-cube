{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74b8f117",
   "metadata": {},
   "source": [
    "# Various linear regressions using extracted features\n",
    "\n",
    "In this notebook, we investigate which of our extracted features may be useful in an attempt to find a model. Unfortunately, linear regression did not appear to help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "33080558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "defcfd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various useful functions\n",
    "\n",
    "def get_mae(az_true, zen_true, az_pred, zen_pred): \n",
    "    \"\"\"\n",
    "    Given a predicted and true azimuth and zenith, compute the mae (mean angular error)\n",
    "    \"\"\"    \n",
    "    if not (np.all(np.isfinite(az_true)) and\n",
    "            np.all(np.isfinite(zen_true)) and\n",
    "            np.all(np.isfinite(az_pred)) and\n",
    "            np.all(np.isfinite(zen_pred))):\n",
    "        raise ValueError(\"All arguments must be finite\")\n",
    "    \n",
    "    # pre-compute all sine and cosine values\n",
    "    sa1 = np.sin(az_true)\n",
    "    ca1 = np.cos(az_true)\n",
    "    sz1 = np.sin(zen_true)\n",
    "    cz1 = np.cos(zen_true)\n",
    "    \n",
    "    sa2 = np.sin(az_pred)\n",
    "    ca2 = np.cos(az_pred)\n",
    "    sz2 = np.sin(zen_pred)\n",
    "    cz2 = np.cos(zen_pred)\n",
    "    \n",
    "    # scalar product of the two cartesian vectors (x = sz*ca, y = sz*sa, z = cz)\n",
    "    scalar_prod = sz1*sz2*(ca1*ca2 + sa1*sa2) + (cz1*cz2)\n",
    "    \n",
    "    # scalar product of two unit vectors is always between -1 and 1, this is against nummerical instability\n",
    "    # that might otherwise occure from the finite precision of the sine and cosine functions\n",
    "    scalar_prod =  np.clip(scalar_prod, -1, 1)\n",
    "    \n",
    "    # convert back to an angle (in radian)\n",
    "    return np.average(np.abs(np.arccos(scalar_prod)))\n",
    "\n",
    "def mae(y_true, y_pred): \n",
    "    return get_mae(y_true[0], y_true[1], y_pred[0], y_pred[1])\n",
    "\n",
    "def get_maes(y_pred, y_true): \n",
    "    \"\"\"\n",
    "    Given a list of predictions and true values of azimuth and zenith, compute mae\n",
    "    \"\"\"\n",
    "    n = len(y_pred)\n",
    "    maes = np.zeros(n)\n",
    "    for i in range (0,n):\n",
    "        az_true = y_true[i][0]\n",
    "        ze_true = y_true[i][1]\n",
    "        az_pred = y_pred[i][0]\n",
    "        ze_pred = y_pred[i][1]\n",
    "        mae = get_mae(az_true, ze_true, az_pred, ze_pred)\n",
    "        maes[i] = mae\n",
    "        \n",
    "    return maes.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "8bb9bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "event_data = pd.read_csv(\"C:/Users/k_vsl/Documents/Erdos/Boot Camp/ice-cube-katja/features-final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "6444fa42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event_id', 'vx_t', 'vy_t', 'vz_t', 'az_t_pred', 'ze_t_pred', 'mae_t',\n",
       "       'mse_squared', 'mse', 'vx_pca', 'vy_pca', 'vz_pca', 'az_pca_pred',\n",
       "       'ze_pca_pred', 'az_true', 'ze_true', 'num_clusters', 'dot_product',\n",
       "       'mse_cat', 'cat_1.0', 'cat_2.0', 'cat_3.0', 'cat_4.0', 'cat_5.0',\n",
       "       'cat_6.0', 'cat_7.0', 'cat_8.0', 'cat_9.0', 'cat_10.0', 'cat_11.0',\n",
       "       'per_x', 'per_y', 'per_z', 'cat_x', 'cat_y', 'cat_z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "a9184170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate training parameters into features and output\n",
    "X = event_data\n",
    "X = X.set_index(\"event_id\")\n",
    "y = event_data[['event_id', 'az_true', 'ze_true']]\n",
    "y = y.set_index(\"event_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "4fe1fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out a final training set\n",
    "# random seed = 134\n",
    "# test size = 25%\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "                                                             shuffle = True,\n",
    "                                                             random_state = 134, \n",
    "                                                             test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "d6c17c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross validation\n",
    "# this cell imitates the erdos lectures notes on kfold cross validation , k = 5\n",
    "# random seed to all splits random_seed = 134\n",
    "kfold = KFold(n_splits = 5,\n",
    "             shuffle = True,\n",
    "             random_state = 134)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "4cc67341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run sklearn Linear Regression\n",
    "def run_lr(V, w, features): \n",
    "    lr = LinearRegression(copy_X = True)\n",
    "    V_train = V[features]\n",
    "    w_train = w\n",
    "    \n",
    "    i = 0\n",
    "    maes = np.zeros(5)\n",
    "    \n",
    "    for train_index, test_index in kfold.split(V_train, w_train):\n",
    "        ## get the kfold training data\n",
    "        V_train_train = V_train.iloc[train_index,:]\n",
    "        w_train_train = w_train.iloc[train_index]\n",
    "    \n",
    "        ## get the holdout data\n",
    "        V_holdout = V_train.iloc[test_index,:]\n",
    "        w_holdout = w_train.iloc[test_index]\n",
    "    \n",
    "        lr.fit(V_train_train, w_train_train)\n",
    "        w_pred = lr.predict(V_holdout)\n",
    "        mae = get_maes(w_pred, w_holdout.values)   \n",
    "    \n",
    "        maes[i] = mae\n",
    "        i += 1\n",
    "    \n",
    "    return maes.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "46e66a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run sklearn SGDRegression with epsilon_insensitive\n",
    "def run_sgd(V, w, features, loss_fun): \n",
    "    model_az = SGDRegressor(loss = loss_fun, max_iter = 50000)\n",
    "    model_ze = SGDRegressor(loss = loss_fun, max_iter = 50000)\n",
    "    \n",
    "    V_train = V[features]\n",
    "    w_train_az = w['az_true']\n",
    "    w_train_ze = w['ze_true']\n",
    "    \n",
    "    i = 0\n",
    "    maes = np.zeros(5)\n",
    "    \n",
    "    for train_index, test_index in kfold.split(V_train, w_train_az):\n",
    "        ## get the kfold training data\n",
    "        V_train_train = V_train.iloc[train_index,:]\n",
    "        w_train_train_az = w_train_az.iloc[train_index]\n",
    "        w_train_train_ze = w_train_ze.iloc[train_index]\n",
    "    \n",
    "        ## get the holdout data\n",
    "        V_holdout = V_train.iloc[test_index,:]\n",
    "        w_holdout_az = w_train_az.iloc[test_index]\n",
    "        w_holdout_ze = w_train_ze.iloc[test_index]\n",
    "\n",
    "        model_az.fit(V_train_train, w_train_train_az)\n",
    "        model_ze.fit(V_train_train, w_train_train_ze)\n",
    "        w_pred_az = model_az.predict(V_holdout)\n",
    "        w_pred_ze = model_ze.predict(V_holdout)\n",
    "        w_pred = np.zeros((len(w_holdout_az), 2))\n",
    "        w_true = np.zeros((len(w_holdout_ze), 2))\n",
    "        w_pred[:,0] = w_pred_az\n",
    "        w_pred[:,1] = w_pred_ze\n",
    "        w_true[:,0] = w_holdout_az\n",
    "        w_true[:,1] = w_holdout_ze\n",
    "        mae = get_maes(w_pred, w_true) \n",
    "    \n",
    "        maes[i] = mae\n",
    "        i += 1\n",
    "    \n",
    "    return maes.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "d49a2686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: 1.2134628158840939\n"
     ]
    }
   ],
   "source": [
    "# Model 1: No Linear Regression\n",
    "# Just use the time best fit line and average the mae's from the line itself\n",
    "print(\"Model 1: \" + str(X_val.mae_t.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "01c96613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: ['az_t_pred', 'ze_t_pred'], the MAE is 1.5114392346721135\n",
      "Using features: ['az_t_pred', 'ze_t_pred', 'num_clusters'], the MAE is 1.5091467497314988\n",
      "Using features: ['az_t_pred', 'ze_t_pred', 'mse'], the MAE is 1.5100998640596575\n",
      "Using features: ['az_t_pred', 'ze_t_pred', 'dot_product'], the MAE is 1.5096530615494284\n",
      "Using features: ['az_t_pred', 'ze_t_pred', 'az_pca_pred', 'ze_pca_pred'], the MAE is 1.5105590649667482\n",
      "Using features: ['az_t_pred', 'ze_t_pred', 'mse_cat'], the MAE is 1.5094332297633348\n",
      "Using features: ['az_pca_pred', 'ze_pca_pred'], the MAE is 1.5219531894197487\n",
      "Using features: ['az_t_pred', 'ze_t_pred', 'cat_1.0', 'cat_2.0', 'cat_3.0', 'cat_4.0', 'cat_5.0', 'cat_6.0', 'cat_7.0', 'cat_8.0', 'cat_9.0', 'cat_10.0'], the MAE is 1.507800883963829\n",
      "Using features: ['az_t_pred', 'ze_t_pred', 'cat_x', 'cat_y', 'cat_z', 'mse', 'cat_1.0', 'cat_2.0', 'cat_3.0', 'cat_4.0', 'cat_5.0', 'cat_6.0', 'cat_7.0', 'cat_8.0', 'cat_9.0', 'cat_10.0'], the MAE is 1.5067696839319975\n",
      "Using features: ['az_t_pred', 'ze_t_pred', 'cat_x', 'cat_y', 'cat_z', 'mse_cat', 'cat_1.0', 'cat_2.0', 'cat_3.0', 'cat_4.0', 'cat_5.0', 'cat_6.0', 'cat_7.0', 'cat_8.0', 'cat_9.0', 'cat_10.0'], the MAE is 1.5064680472951655\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression models\n",
    "features = [['az_t_pred', 'ze_t_pred'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'num_clusters'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'mse'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'dot_product'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'az_pca_pred', 'ze_pca_pred'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'mse_cat'], \n",
    "            ['az_pca_pred', 'ze_pca_pred'],\n",
    "            ['az_t_pred', 'ze_t_pred','cat_1.0','cat_2.0', 'cat_3.0', 'cat_4.0', 'cat_5.0', 'cat_6.0', 'cat_7.0','cat_8.0', 'cat_9.0', 'cat_10.0'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'cat_x', 'cat_y', 'cat_z', 'mse', 'cat_1.0','cat_2.0', 'cat_3.0', 'cat_4.0', 'cat_5.0', 'cat_6.0', 'cat_7.0','cat_8.0', 'cat_9.0', 'cat_10.0'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'cat_x', 'cat_y', 'cat_z', 'mse_cat', 'cat_1.0','cat_2.0', 'cat_3.0', 'cat_4.0', 'cat_5.0', 'cat_6.0', 'cat_7.0','cat_8.0', 'cat_9.0', 'cat_10.0']\n",
    "        ]\n",
    "\n",
    "\n",
    "n = len(features)\n",
    "maes = np.zeros(n)\n",
    "\n",
    "i = 0\n",
    "for i in range(0,n):\n",
    "    mae = run_lr(X_train, y_train, features[i])\n",
    "    maes[i] = mae\n",
    "    print(\"Using features: \" + str(features[i]) + \", the MAE is \" + str(mae))\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6204ed2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: ['az_t_pred', 'ze_t_pred'], the MAE is 1.461555593845072\n",
      "Using features: ['az_t_pred', 'ze_t_pred', 'num_clusters'], the MAE is 1.45741346561603\n",
      "Using features: ['az_t_pred', 'ze_t_pred', 'mse'], the MAE is 1.5649012556033466\n",
      "Using features: ['az_t_pred', 'ze_t_pred', 'dot_product'], the MAE is 1.460313197178092\n"
     ]
    }
   ],
   "source": [
    "# SGDRegression with loss = 'epsilon_insensitive'\n",
    "\n",
    "features = [['az_t_pred', 'ze_t_pred'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'num_clusters'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'mse'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'dot_product'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'az_pca_pred', 'ze_pca_pred'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'mse_cat'], \n",
    "            ['az_pca_pred', 'ze_pca_pred'],\n",
    "            ['az_t_pred', 'ze_t_pred','cat_1.0','cat_2.0', 'cat_3.0', 'cat_4.0', 'cat_5.0', 'cat_6.0', 'cat_7.0','cat_8.0', 'cat_9.0', 'cat_10.0'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'cat_x', 'cat_y', 'cat_z', 'mse', 'cat_1.0','cat_2.0', 'cat_3.0', 'cat_4.0', 'cat_5.0', 'cat_6.0', 'cat_7.0','cat_8.0', 'cat_9.0', 'cat_10.0'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'cat_x', 'cat_y', 'cat_z', 'mse_cat', 'cat_1.0','cat_2.0', 'cat_3.0', 'cat_4.0', 'cat_5.0', 'cat_6.0', 'cat_7.0','cat_8.0', 'cat_9.0', 'cat_10.0']\n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "n = len(features)\n",
    "maes_sgd = np.zeros(n)\n",
    "\n",
    "i = 0\n",
    "for i in range(0,n):\n",
    "    mae = run_sgd(X_train, y_train, features[i], 'epsilon_insensitive')\n",
    "    maes_sgd[i] = mae\n",
    "    print(\"Using features: \" + str(features[i]) + \", the MAE is \" + str(mae))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a32e9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGDRegression with loss = 'huber'\n",
    "\n",
    "features = [['az_t_pred', 'ze_t_pred'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'num_clusters'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'mse'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'dot_product'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'az_pca_pred', 'ze_pca_pred'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'mse_cat'], \n",
    "            ['az_pca_pred', 'ze_pca_pred'],\n",
    "            ['az_t_pred', 'ze_t_pred','cat_1.0','cat_2.0', 'cat_3.0', 'cat_4.0', 'cat_5.0', 'cat_6.0', 'cat_7.0','cat_8.0', 'cat_9.0', 'cat_10.0'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'cat_x', 'cat_y', 'cat_z', 'mse', 'cat_1.0','cat_2.0', 'cat_3.0', 'cat_4.0', 'cat_5.0', 'cat_6.0', 'cat_7.0','cat_8.0', 'cat_9.0', 'cat_10.0'], \n",
    "            ['az_t_pred', 'ze_t_pred', 'cat_x', 'cat_y', 'cat_z', 'mse_cat', 'cat_1.0','cat_2.0', 'cat_3.0', 'cat_4.0', 'cat_5.0', 'cat_6.0', 'cat_7.0','cat_8.0', 'cat_9.0', 'cat_10.0']\n",
    "        ]\n",
    "\n",
    "\n",
    "n = len(features)\n",
    "maes_sgdh = np.zeros(n)\n",
    "\n",
    "i = 0\n",
    "for i in range(0,n):\n",
    "    mae = run_sgd(X_train, y_train, features[i], 'huber')\n",
    "    maes_sgdh[i] = mae\n",
    "    print(\"Using features: \" + str(features[i]) + \", the MAE is \" + str(mae))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "789b048a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.50740675 1.5082165  1.51644227 1.51144212 1.51368853]\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Linear regression on the az and ze predicted by the time best fit line\n",
    "features = ['az_t_pred', 'ze_t_pred']\n",
    "mae = run_lr(X_train, y_train, features)\n",
    "\n",
    "lr_2 = LinearRegression(copy_X = True)\n",
    "\n",
    "X_train_2 = X_train[['az_t_pred', 'ze_t_pred']]\n",
    "y_train_2 = y_train\n",
    "\n",
    "mae_2 = np.zeros(5)\n",
    " \n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train_2, y_train_2):\n",
    "    ## get the kfold training data\n",
    "    X_train_train_2 = X_train_2.iloc[train_index,:]\n",
    "    y_train_train_2 = y_train_2.iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = X_train_2.iloc[test_index,:]\n",
    "    y_holdout = y_train_2.iloc[test_index]\n",
    "    \n",
    "    lr_2.fit(X_train_train_2, y_train_train_2)\n",
    "    y_pred = lr_2.predict(X_holdout)\n",
    "    mae = get_maes(y_pred, y_holdout.values)   \n",
    "    \n",
    "    mae_2[i] = mae\n",
    "    i += 1\n",
    "\n",
    "print(mae_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "8bde8ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.50534555 1.50573215 1.51397336 1.50915352 1.51152918]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5091467497314988"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 3: Linear regression on the az and ze predicted by the time best fit line, in addition to clustering\n",
    "lr_3 = LinearRegression(copy_X = True)\n",
    "X_train_3 = X_train[['az_t_pred', 'ze_t_pred', 'num_clusters']]\n",
    "y_train_3 = y_train\n",
    "\n",
    "mae_3 = np.zeros(5)\n",
    " \n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train_3, y_train_3):\n",
    "    ## get the kfold training data\n",
    "    X_train_train_3 = X_train_3.iloc[train_index,:]\n",
    "    y_train_train_3 = y_train_3.iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = X_train_3.iloc[test_index,:]\n",
    "    y_holdout = y_train_3.iloc[test_index]\n",
    "    \n",
    "    lr_3.fit(X_train_train_3, y_train_train_3)\n",
    "    y_pred = lr_3.predict(X_holdout)\n",
    "    mae = get_maes(y_pred, y_holdout.values)   \n",
    "    \n",
    "    mae_3[i] = mae\n",
    "    i += 1\n",
    "\n",
    "print(mae_3)\n",
    "mae_3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "6b898895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.50605267 1.50692562 1.51505989 1.51034495 1.51211618]\n"
     ]
    }
   ],
   "source": [
    "# Model 4: Linear regression on the az and ze predicted by the time best fit line, in addtion to the mse value\n",
    "lr_4 = LinearRegression(copy_X = True)\n",
    "X_train_4 = X_train[['az_t_pred', 'ze_t_pred', 'mse']]\n",
    "y_train_4 = y_train\n",
    "\n",
    "mae_4 = np.zeros(5)\n",
    " \n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train_4, y_train_4):\n",
    "    ## get the kfold training data\n",
    "    X_train_train_4 = X_train_4.iloc[train_index,:]\n",
    "    y_train_train_4 = y_train_4.iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = X_train_4.iloc[test_index,:]\n",
    "    y_holdout = y_train_4.iloc[test_index]\n",
    "    \n",
    "    lr_4.fit(X_train_train_4, y_train_train_4)\n",
    "    y_pred = lr_4.predict(X_holdout)\n",
    "    mae = get_maes(y_pred, y_holdout.values)   \n",
    "    \n",
    "    mae_4[i] = mae\n",
    "    i += 1\n",
    "\n",
    "print(mae_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "b634431f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.50603265 1.50656034 1.51439981 1.50947405 1.51179846]\n"
     ]
    }
   ],
   "source": [
    "# Model 5: Linear regression on the az and ze predicted by the time best fit line, in addtion to the dot product\n",
    "lr_5 = LinearRegression(copy_X = True)\n",
    "X_train_5 = X_train[['az_t_pred', 'ze_t_pred', 'dot_product']]\n",
    "y_train_5 = y_train\n",
    "\n",
    "mae_5 = np.zeros(5)\n",
    " \n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train_5, y_train_5):\n",
    "    ## get the kfold training data\n",
    "    X_train_train_5 = X_train_5.iloc[train_index,:]\n",
    "    y_train_train_5 = y_train_5.iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = X_train_5.iloc[test_index,:]\n",
    "    y_holdout = y_train_5.iloc[test_index]\n",
    "    \n",
    "    lr_5.fit(X_train_train_5, y_train_train_5)\n",
    "    y_pred = lr_5.predict(X_holdout)\n",
    "    mae = get_maes(y_pred, y_holdout.values)   \n",
    "    \n",
    "    mae_5[i] = mae\n",
    "    i += 1\n",
    "\n",
    "print(mae_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "b45207a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.50632911 1.50733308 1.5156     1.51075943 1.51277371]\n"
     ]
    }
   ],
   "source": [
    "# Model 6: Linear regression on the az and ze predicted by the time best fit line, in addition to the pca best fit line\n",
    "lr_6 = LinearRegression(copy_X = True)\n",
    "X_train_6 = X_train[['az_t_pred', 'ze_t_pred', 'az_pca_pred', 'ze_pca_pred']]\n",
    "y_train_6 = y_train\n",
    "\n",
    "mae_6 = np.zeros(5)\n",
    " \n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train_6, y_train_6):\n",
    "    ## get the kfold training data\n",
    "    X_train_train_6 = X_train_6.iloc[train_index,:]\n",
    "    y_train_train_6 = y_train_6.iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = X_train_6.iloc[test_index,:]\n",
    "    y_holdout = y_train_6.iloc[test_index]\n",
    "    \n",
    "    lr_6.fit(X_train_train_6, y_train_train_6)\n",
    "    y_pred = lr_6.predict(X_holdout)\n",
    "    mae = get_maes(y_pred, y_holdout.values)   \n",
    "    \n",
    "    mae_6[i] = mae\n",
    "    i += 1\n",
    "\n",
    "print(mae_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "ac3b34ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.50584927 1.50610422 1.51399367 1.50961388 1.51160511]\n"
     ]
    }
   ],
   "source": [
    "# Model 7: Linear regression on the az and ze predicted by the time best fit line, in addtion to treating mse as categorical variable\n",
    "\n",
    "# Get categorical variable\n",
    "lr_7 = LinearRegression(copy_X = True)\n",
    "X_train_7 = X_train[['az_t_pred', 'ze_t_pred', 'mse_cat']]\n",
    "y_train_7 = y_train\n",
    " \n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train_7, y_train_7):\n",
    "    ## get the kfold training data\n",
    "    X_train_train_7 = X_train_7.iloc[train_index,:]\n",
    "    y_train_train_7 = y_train_7.iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = X_train_7.iloc[test_index,:]\n",
    "    y_holdout = y_train_7.iloc[test_index]\n",
    "    \n",
    "    lr_7.fit(X_train_train_7, y_train_train_7)\n",
    "    y_pred = lr_7.predict(X_holdout)\n",
    "    mae = get_maes(y_pred, y_holdout.values)   \n",
    "    mae_7[i] = mae\n",
    "    i += 1\n",
    "\n",
    "print(mae_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "f39f021a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.51720295 1.51869047 1.52736457 1.52278137 1.52372659]\n"
     ]
    }
   ],
   "source": [
    "# Model 8: Just using linear regression on az and ze predicted by pca best fit line\n",
    "lr_8 = LinearRegression(copy_X = True)\n",
    "\n",
    "X_train_8 = X_train[['az_pca_pred', 'ze_pca_pred']]\n",
    "y_train_8 = y_train\n",
    "\n",
    "mae_8 = np.zeros(5)\n",
    " \n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train_8, y_train_8):\n",
    "    ## get the kfold training data\n",
    "    X_train_train_8 = X_train_8.iloc[train_index,:]\n",
    "    y_train_train_8 = y_train_8.iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = X_train_8.iloc[test_index,:]\n",
    "    y_holdout = y_train_8.iloc[test_index]\n",
    "    \n",
    "    lr_8.fit(X_train_train_8, y_train_train_8)\n",
    "    y_pred = lr_8.predict(X_holdout)\n",
    "    mae = get_maes(y_pred, y_holdout.values)   \n",
    "    \n",
    "    mae_8[i] = mae\n",
    "    i += 1\n",
    "\n",
    "print(mae_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "8418325c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.50397942 1.50464298 1.51234034 1.50790023 1.51014145]\n"
     ]
    }
   ],
   "source": [
    "# Model 9: Using clustering as a categorical variable\n",
    "lr_9 = LinearRegression(copy_X = True)\n",
    "\n",
    "X_train_9 = X_train[['az_t_pred', 'ze_t_pred','cat_1.0',\n",
    "       'cat_2.0', 'cat_3.0', 'cat_4.0', 'cat_5.0', 'cat_6.0', 'cat_7.0',\n",
    "       'cat_8.0', 'cat_9.0', 'cat_10.0']]\n",
    "y_train_9 = y_train\n",
    "\n",
    "mae_9 = np.zeros(5)\n",
    " \n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train_9, y_train_9):\n",
    "    ## get the kfold training data\n",
    "    X_train_train_9 = X_train_9.iloc[train_index,:]\n",
    "    y_train_train_9 = y_train_9.iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = X_train_9.iloc[test_index,:]\n",
    "    y_holdout = y_train_9.iloc[test_index]\n",
    "    \n",
    "    lr_9.fit(X_train_train_9, y_train_train_9)\n",
    "    y_pred = lr_9.predict(X_holdout)\n",
    "    mae = get_maes(y_pred, y_holdout.values)   \n",
    "    \n",
    "    mae_9[i] = mae\n",
    "    i += 1\n",
    "\n",
    "print(mae_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "ad2cbd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.50682839 1.50778389 1.51570358 1.51068535 1.51299756]\n"
     ]
    }
   ],
   "source": [
    "# Model 10 Using the biased sides of sensors\n",
    "lr_10 = LinearRegression(copy_X = True)\n",
    "\n",
    "X_train_10 = X_train[['az_t_pred', 'ze_t_pred', 'cat_x', 'cat_y', 'cat_z']]\n",
    "y_train_10 = y_train\n",
    "\n",
    "mae_10 = np.zeros(5)\n",
    " \n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train_10, y_train_10):\n",
    "    ## get the kfold training data\n",
    "    X_train_train_10 = X_train_10.iloc[train_index,:]\n",
    "    y_train_train_10 = y_train_10.iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = X_train_10.iloc[test_index,:]\n",
    "    y_holdout = y_train_10.iloc[test_index]\n",
    "    \n",
    "    lr_10.fit(X_train_train_10, y_train_train_10)\n",
    "    y_pred = lr_10.predict(X_holdout)\n",
    "    mae = get_maes(y_pred, y_holdout.values)   \n",
    "    \n",
    "    mae_10[i] = mae\n",
    "    i += 1\n",
    "\n",
    "print(mae_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "db33bce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.50525599 1.50567671 1.51326882 1.50885468 1.51092673]\n"
     ]
    }
   ],
   "source": [
    "# Model 11: Using biased sides + categorical variables for side and mse\n",
    "lr_11 = LinearRegression(copy_X = True)\n",
    "\n",
    "X_train_11 = X_train[['az_t_pred', 'ze_t_pred', 'cat_x', 'cat_y', 'cat_z', 'mse_cat']]\n",
    "y_train_11 = y_train\n",
    "\n",
    "mae_11 = np.zeros(5)\n",
    " \n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train_11, y_train_11):\n",
    "    ## get the kfold training data\n",
    "    X_train_train_11 = X_train_11.iloc[train_index,:]\n",
    "    y_train_train_11 = y_train_11.iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = X_train_11.iloc[test_index,:]\n",
    "    y_holdout = y_train_11.iloc[test_index]\n",
    "    \n",
    "    lr_11.fit(X_train_train_11, y_train_train_11)\n",
    "    y_pred = lr_11.predict(X_holdout)\n",
    "    mae = get_maes(y_pred, y_holdout.values)   \n",
    "    \n",
    "    mae_11[i] = mae\n",
    "    i += 1\n",
    "\n",
    "print(mae_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "6aefc279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.50294107 1.50351744 1.51067776 1.50649056 1.50871341]\n"
     ]
    }
   ],
   "source": [
    "# Model 12: Using time best fit + all categorical variables\n",
    "lr_12 = LinearRegression(copy_X = True)\n",
    "\n",
    "X_train_12 = X_train[['az_t_pred', 'ze_t_pred', 'cat_x', 'cat_y', 'cat_z', 'mse_cat', 'cat_1.0',\n",
    "       'cat_2.0', 'cat_3.0', 'cat_4.0', 'cat_5.0', 'cat_6.0', 'cat_7.0',\n",
    "       'cat_8.0', 'cat_9.0', 'cat_10.0']]\n",
    "y_train_12 = y_train\n",
    "\n",
    "mae_12 = np.zeros(5)\n",
    " \n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train_12, y_train_12):\n",
    "    ## get the kfold training data\n",
    "    X_train_train_12 = X_train_12.iloc[train_index,:]\n",
    "    y_train_train_12 = y_train_12.iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = X_train_12.iloc[test_index,:]\n",
    "    y_holdout = y_train_12.iloc[test_index]\n",
    "    \n",
    "    lr_12.fit(X_train_train_12, y_train_train_12)\n",
    "    y_pred = lr_12.predict(X_holdout)\n",
    "    mae = get_maes(y_pred, y_holdout.values)   \n",
    "    \n",
    "    mae_12[i] = mae\n",
    "    i += 1\n",
    "\n",
    "print(mae_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "3c28ee94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.50300838 1.5038687  1.51121546 1.50680626 1.50894962]\n"
     ]
    }
   ],
   "source": [
    "# Model 13: Same as model 12 but using actual MSE\n",
    "lr_13 = LinearRegression(copy_X = True)\n",
    "\n",
    "X_train_13 = X_train[['az_t_pred', 'ze_t_pred', 'cat_x', 'cat_y', 'cat_z', 'mse', 'cat_1.0',\n",
    "       'cat_2.0', 'cat_3.0', 'cat_4.0', 'cat_5.0', 'cat_6.0', 'cat_7.0',\n",
    "       'cat_8.0', 'cat_9.0', 'cat_10.0']]\n",
    "y_train_13 = y_train\n",
    "\n",
    "mae_13 = np.zeros(5)\n",
    " \n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train_13, y_train_13):\n",
    "    ## get the kfold training data\n",
    "    X_train_train_13 = X_train_13.iloc[train_index,:]\n",
    "    y_train_train_13 = y_train_13.iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = X_train_13.iloc[test_index,:]\n",
    "    y_holdout = y_train_13.iloc[test_index]\n",
    "    \n",
    "    lr_13.fit(X_train_train_13, y_train_train_13)\n",
    "    y_pred = lr_13.predict(X_holdout)\n",
    "    mae = get_maes(y_pred, y_holdout.values)   \n",
    "    \n",
    "    mae_13[i] = mae\n",
    "    i += 1\n",
    "\n",
    "print(mae_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "e793ca88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: 1.2137944928512907\n",
      "Model 2: 1.5114392346721135\n",
      "Model 3: 1.5091467497314988\n",
      "Model 4: 1.5100998640596575\n",
      "Model 5: 1.5096530615494284\n",
      "Model 6: 1.5105590649667482\n",
      "Model 7: 1.5094332297633348\n",
      "Model 8: 1.5219531894197487\n",
      "Model 9: 1.507800883963829\n",
      "Model 10: 1.5107997525418733\n",
      "Model 11: 1.5087965866205237\n",
      "Model 12: 1.5064680472951655\n",
      "Model 13: 1.5067696839319975\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 1: \" + str(mae_1.mean()))\n",
    "print(\"Model 2: \" + str(mae_2.mean()))\n",
    "print(\"Model 3: \" + str(mae_3.mean()))\n",
    "print(\"Model 4: \" + str(mae_4.mean()))\n",
    "print(\"Model 5: \" + str(mae_5.mean()))\n",
    "print(\"Model 6: \" + str(mae_6.mean()))\n",
    "print(\"Model 7: \" + str(mae_7.mean()))\n",
    "print(\"Model 8: \" + str(mae_8.mean()))\n",
    "print(\"Model 9: \" + str(mae_9.mean()))\n",
    "print(\"Model 10: \" + str(mae_10.mean()))\n",
    "print(\"Model 11: \" + str(mae_11.mean()))\n",
    "print(\"Model 12: \" + str(mae_12.mean()))\n",
    "print(\"Model 13: \" + str(mae_13.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "7dc97df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try linear regression with custom loss function\n",
    "from sklearn.linear_model import SGDRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "188b42fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.46446438 1.45966545 1.46088716 1.47005354 1.46105984]\n"
     ]
    }
   ],
   "source": [
    "# Model 2 with SGDRegressor\n",
    "model_az = SGDRegressor(loss = 'epsilon_insensitive', max_iter = 50000)\n",
    "model_ze = SGDRegressor(loss = 'epsilon_insensitive', max_iter = 50000)\n",
    "\n",
    "X_train_2 = X_train[['az_t_pred', 'ze_t_pred']]\n",
    "y_train_az = y_train['az_true']\n",
    "y_train_ze = y_train['ze_true']\n",
    "\n",
    "mae2 = np.zeros(5)\n",
    " \n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train_2, y_train_az):\n",
    "    ## get the kfold training data\n",
    "    X_train_train_2 = X_train_2.iloc[train_index,:]\n",
    "    y_train_train_az = y_train_az.iloc[train_index]\n",
    "    y_train_train_ze = y_train_ze.iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = X_train_2.iloc[test_index,:]\n",
    "    y_holdout_az = y_train_az.iloc[test_index]\n",
    "    y_holdout_ze = y_train_ze.iloc[test_index]\n",
    "    \n",
    "    model_az.fit(X_train_train_2, y_train_train_az)\n",
    "    model_ze.fit(X_train_train_2, y_train_train_ze)\n",
    "    y_pred_az = model_az.predict(X_holdout)\n",
    "    y_pred_ze = model_ze.predict(X_holdout)\n",
    "    y_pred = np.zeros((len(y_holdout_az), 2))\n",
    "    y_true = np.zeros((len(y_holdout_az), 2))\n",
    "    y_pred[:,0] = y_pred_az\n",
    "    y_pred[:,1] = y_pred_ze\n",
    "    y_true[:,0] = y_holdout_az\n",
    "    y_true[:,1] = y_holdout_ze\n",
    "    mae = get_maes(y_pred, y_true)   \n",
    "    \n",
    "    mae2[i] = mae\n",
    "    i += 1\n",
    "\n",
    "print(mae2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "0b6806e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.45403883 1.45593671 1.46064882 1.45614789 1.45751829]\n"
     ]
    }
   ],
   "source": [
    "# Model 2 with SGDRegressor\n",
    "model_az = SGDRegressor(loss = 'huber', max_iter = 50000)\n",
    "model_ze = SGDRegressor(loss = 'huber', max_iter = 50000)\n",
    "\n",
    "X_train_2 = X_train[['az_t_pred', 'ze_t_pred']]\n",
    "y_train_az = y_train['az_true']\n",
    "y_train_ze = y_train['ze_true']\n",
    "\n",
    "mae3 = np.zeros(5)\n",
    " \n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train_2, y_train_az):\n",
    "    ## get the kfold training data\n",
    "    X_train_train_2 = X_train_2.iloc[train_index,:]\n",
    "    y_train_train_az = y_train_az.iloc[train_index]\n",
    "    y_train_train_ze = y_train_ze.iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = X_train_2.iloc[test_index,:]\n",
    "    y_holdout_az = y_train_az.iloc[test_index]\n",
    "    y_holdout_ze = y_train_ze.iloc[test_index]\n",
    "    \n",
    "    model_az.fit(X_train_train_2, y_train_train_az)\n",
    "    model_ze.fit(X_train_train_2, y_train_train_ze)\n",
    "    y_pred_az = model_az.predict(X_holdout)\n",
    "    y_pred_ze = model_ze.predict(X_holdout)\n",
    "    y_pred = np.zeros((len(y_holdout_az), 2))\n",
    "    y_true = np.zeros((len(y_holdout_az), 2))\n",
    "    y_pred[:,0] = y_pred_az\n",
    "    y_pred[:,1] = y_pred_ze\n",
    "    y_true[:,0] = y_holdout_az\n",
    "    y_true[:,1] = y_holdout_ze\n",
    "    mae = get_maes(y_pred, y_true)   \n",
    "    \n",
    "    mae3[i] = mae\n",
    "    i += 1\n",
    "\n",
    "print(mae3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "eaa322e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.57917627 1.569862   1.58042174 1.57101033 1.56666928]\n"
     ]
    }
   ],
   "source": [
    "# Trying some other models\n",
    "model_az = SGDRegressor(loss = 'epsilon_insensitive', max_iter = 50000)\n",
    "model_ze = SGDRegressor(loss = 'epsilon_insensitive', max_iter = 50000)\n",
    "\n",
    "X_train_2 = X_train[['az_t_pred', 'ze_t_pred', 'cat_x', 'cat_y', 'cat_z', 'mse', 'cat_1.0',\n",
    "       'cat_2.0', 'cat_3.0', 'cat_4.0', 'cat_5.0', 'cat_6.0', 'cat_7.0',\n",
    "       'cat_8.0', 'cat_9.0', 'cat_10.0']]\n",
    "y_train_az = y_train['az_true']\n",
    "y_train_ze = y_train['ze_true']\n",
    "\n",
    "mae4 = np.zeros(5)\n",
    " \n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train_2, y_train_az):\n",
    "    ## get the kfold training data\n",
    "    X_train_train_2 = X_train_2.iloc[train_index,:]\n",
    "    y_train_train_az = y_train_az.iloc[train_index]\n",
    "    y_train_train_ze = y_train_ze.iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = X_train_2.iloc[test_index,:]\n",
    "    y_holdout_az = y_train_az.iloc[test_index]\n",
    "    y_holdout_ze = y_train_ze.iloc[test_index]\n",
    "    \n",
    "    model_az.fit(X_train_train_2, y_train_train_az)\n",
    "    model_ze.fit(X_train_train_2, y_train_train_ze)\n",
    "    y_pred_az = model_az.predict(X_holdout)\n",
    "    y_pred_ze = model_ze.predict(X_holdout)\n",
    "    y_pred = np.zeros((len(y_holdout_az), 2))\n",
    "    y_true = np.zeros((len(y_holdout_az), 2))\n",
    "    y_pred[:,0] = y_pred_az\n",
    "    y_pred[:,1] = y_pred_ze\n",
    "    y_true[:,0] = y_holdout_az\n",
    "    y_true[:,1] = y_holdout_ze\n",
    "    mae = get_maes(y_pred, y_true)   \n",
    "    \n",
    "    mae4[i] = mae\n",
    "    i += 1\n",
    "\n",
    "print(mae4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "4663bb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4558522632010233\n"
     ]
    }
   ],
   "source": [
    "print(mae2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "92e5076f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4568581088086567\n"
     ]
    }
   ],
   "source": [
    "print(mae3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "25de00cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\k_vsl\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e0531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
